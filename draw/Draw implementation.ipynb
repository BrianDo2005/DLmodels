{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# HELPER FUNCTIONS #\n",
    "####################\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading MNIST data\n",
    "\n",
    "We are again using the MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "X = mnist.train._images.reshape(55000,784)\n",
    "Y = mnist.train._labels\n",
    "index = np.arange(55000)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "train_bf = draw.BatchFeeder(X[index[:54000]], Y[index[:54000]], 128)\n",
    "valid_bf = draw.BatchFeeder(X[index[54000:]], Y[index[54000:]], 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50572322d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = train_bf.next()\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(x[0].reshape((28,28)), cmap='Greys')\n",
    "plt.yticks([],[])\n",
    "plt.xticks([],[])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAW implementation\n",
    "\n",
    "The code below implements this. https://arxiv.org/pdf/1502.04623.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DRAW:\n",
    "    def __init__(self,\n",
    "                 steps=10,\n",
    "                 dims=[256, 256, 10],\n",
    "                 batchsize=128,\n",
    "                 width=28,\n",
    "                 fn=tf.nn.elu,\n",
    "                 attention = True,\n",
    "                 dropout=1.0):\n",
    "        # Reset all existing tensors\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Define parameters of the encoder\n",
    "        self.dims = dims\n",
    "        #self.fn = fn\n",
    "        self.learning_rate = 0.001\n",
    "        self._dropout = 1.0\n",
    "        self.built = False\n",
    "        self.sesh = tf.Session()\n",
    "        self.e = 0\n",
    "        self.steps = 10 \n",
    "        self.batchsize = batchsize # default to 128\n",
    "        self.attention = attention\n",
    "        self.N = 5 # of filters.\n",
    "        self.width = width\n",
    "        self.inputsize = width**2 # default to 784 for MNIST\n",
    "        self.epsilon = 1e-5        \n",
    "        \n",
    "        # Tracking data\n",
    "        self.learning_curve = []\n",
    "        self.record = {\"cs\":[], \"y\":[], \"mu_x\":[], \"mu_y\":[]}\n",
    "        \n",
    "        # Building the graph\n",
    "        self.ops = self.build()\n",
    "        self.sesh.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def build(self):\n",
    "        if self.built:\n",
    "            return -1\n",
    "        else:\n",
    "            self.built = True\n",
    "            \n",
    "        #########\n",
    "        # MODEL #\n",
    "        #########\n",
    "        \n",
    "        # Some placeholders to define inputs/parameters\n",
    "        x = tf.placeholder(tf.float32, shape=[self.batchsize, self.inputsize], name=\"x\")\n",
    "        dropout = tf.placeholder(tf.float32, shape=[], name=\"dropout_keepprob\")\n",
    "        \n",
    "        # Defining LSTM cells to be used as encoder/decoder \n",
    "        # Change this to have other kinds of reccurent cells.\n",
    "        self.encoder = tf.contrib.rnn.LSTMCell(self.dims[0], state_is_tuple=True, activation=tf.nn.elu)\n",
    "        self.decoder = tf.contrib.rnn.LSTMCell(self.dims[1], state_is_tuple=True, activation=tf.nn.elu)\n",
    "        \n",
    "        # Some initialization on states and inputs\n",
    "        dec_output = tf.zeros((self.batchsize, self.dims[1])) #output from previous decoder\n",
    "        enc_state = self.encoder.zero_state(self.batchsize, tf.float32) # initial state for encoder\n",
    "        dec_state = self.decoder.zero_state(self.batchsize, tf.float32) # initial state for decoder\n",
    "        \n",
    "        # Some lists to keep track of output and latent tensors\n",
    "        canvases = [] # keeps track the current state of canvas\n",
    "        mus = [] # keeps tracks of mus of latent distributions\n",
    "        logsigmas = [] # keeps tracks of log(sigmas) of latent distributions\n",
    "        \n",
    "        reuse = None\n",
    "        # Unrollinng the whole graph\n",
    "        mu_xs = []\n",
    "        mu_ys = []\n",
    "        for i in range(self.steps):\n",
    "            # If it is first iteration, start with brand new canvas\n",
    "            if i == 0:\n",
    "                prev_canvas = tf.zeros((self.batchsize, self.inputsize))\n",
    "            else:\n",
    "                prev_canvas = canvases[-1]\n",
    "\n",
    "            # Calculate the residual in the image\n",
    "            x_hat = x - tf.nn.sigmoid(prev_canvas)\n",
    "            \n",
    "            # read input depends on input shape\n",
    "            if self.attention: \n",
    "                _input = self.read_with_attention(x, x_hat, dec_output, reuse=reuse)\n",
    "            else:\n",
    "                _input = tf.concat([x, x_hat, dec_output], axis=1)\n",
    "                \n",
    "            \n",
    "            # Apply an encoder to it using appropriate reuse term\n",
    "            enc_output, enc_state = self.encode(_input, enc_state, reuse=reuse)\n",
    "            \n",
    "            # Sampling \n",
    "            with tf.variable_scope(\"sampling\", reuse=reuse):\n",
    "                z_mean = tf.contrib.slim.fully_connected(enc_output, self.dims[-1], activation_fn=tf.identity, scope=\"mean\")\n",
    "                z_logsigma = tf.contrib.slim.fully_connected(enc_output, self.dims[-1], activation_fn=tf.identity, scope=\"sigma\")\n",
    "                mus.append(z_mean)\n",
    "                logsigmas.append(z_logsigma)\n",
    "            \n",
    "            z = self.sample(z_mean, z_logsigma)\n",
    "            \n",
    "            # Apply an decoder to latent values.\n",
    "            dec_output, dec_state = self.decode(z, dec_state, reuse=reuse)\n",
    "            \n",
    "            # Apply linear transfromation to dec_output and add to canvas\n",
    "            if self.attention:\n",
    "                temp, mu_x, mu_y = self.write_with_attention(dec_output, reuse)\n",
    "                cur_canvas = prev_canvas + temp\n",
    "                mu_xs.append(mu_x)\n",
    "                mu_ys.append(mu_y)\n",
    "            else:\n",
    "                cur_canvas = prev_canvas + tf.contrib.slim.fully_connected(dec_output,\\\n",
    "                                                                           self.inputsize,\\\n",
    "                                                                           activation_fn=tf.identity,\\\n",
    "                                                                           scope=\"writing\",\\\n",
    "                                                                           reuse=reuse)\n",
    "            # Add to canvas\n",
    "            canvases.append(cur_canvas) \n",
    "            \n",
    "            # Keep reusing the first weights built.\n",
    "            reuse = True\n",
    "            \n",
    "        reconstructed = tf.nn.sigmoid(canvases[-1])\n",
    "            \n",
    "        ########\n",
    "        # LOSS #\n",
    "        ########\n",
    "        \n",
    "        # Defining reconstruction loss\n",
    "        rec_loss = self.crossEntropy(reconstructed, x)\n",
    "        \n",
    "        kl_holder = []\n",
    "        # Defining KL loss\n",
    "        for i in range(self.steps):\n",
    "            kl_holder.append(self.kullbackLeibler(mus[i], logsigmas[i]))\n",
    "        kl_loss = tf.add_n(kl_holder)\n",
    "        \n",
    "        with tf.name_scope(\"cost\"):\n",
    "            # average over minibatch\n",
    "            cost = tf.reduce_mean(rec_loss + kl_loss, name=\"draw_cost\")\n",
    "            \n",
    "        ################\n",
    "        # OPTIMIZATION #\n",
    "        ################\n",
    "        \n",
    "        # Defining optimization procedure.\n",
    "        with tf.name_scope(\"Adam_optimizer\"):\n",
    "            optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "            tvars = tf.trainable_variables()\n",
    "            grads_and_vars = optimizer.compute_gradients(cost, tvars)\n",
    "            # Gradient clipping here.\n",
    "            clipped = [(tf.clip_by_value(grad, -5, 5), tvar) for grad, tvar in grads_and_vars]\n",
    "            train = optimizer.apply_gradients(clipped, name=\"minimize_cost\")\n",
    "            \n",
    "        ############\n",
    "        # SAMPLING # \n",
    "        ############\n",
    "        zs_ = [tf.placeholder_with_default(tf.random_normal([self.batchsize, self.dims[-1]]),\n",
    "                                            shape=[self.batchsize, self.dims[-1]],\n",
    "                                            name=\"latent_input\") for _ in range(self.steps)]\n",
    "        dec_state = self.decoder.zero_state(self.batchsize, tf.float32) # initial state for decoder\n",
    "        cs_ = []\n",
    "        mu_xs_ = []\n",
    "        mu_ys_ = []\n",
    "        for i in range(self.steps):\n",
    "            if i == 0:\n",
    "                prev_canvas = tf.zeros((self.batchsize, self.inputsize))\n",
    "            else:\n",
    "                prev_canvas = cs_[-1]\n",
    "            dec_output, dec_state = self.decode(zs_[i], dec_state, reuse=True)\n",
    "            if self.attention:\n",
    "                temp, mu_x, mu_y = self.write_with_attention(dec_output, reuse)\n",
    "                cur_canvas = prev_canvas + temp\n",
    "                mu_xs_.append(mu_x)\n",
    "                mu_ys_.append(mu_y)\n",
    "            else:\n",
    "                cur_canvas = prev_canvas + tf.contrib.slim.fully_connected(dec_output,\\\n",
    "                                                                           self.inputsize,\\\n",
    "                                                                           activation_fn=tf.identity,\\\n",
    "                                                                           scope=\"writing\",\\\n",
    "                                                                           reuse=True)\n",
    "            cs_.append(cur_canvas)\n",
    "        \n",
    "            \n",
    "        # Exporting out the operaions as dictionary\n",
    "        return dict(\n",
    "            dropout_keepprob = dropout,\n",
    "            x = x,  \n",
    "            z_mean = z_mean, \n",
    "            z_logsigma = z_logsigma,\n",
    "            latent_input = zs_,\n",
    "            reconstructed = canvases,\n",
    "            reconstructed_ = cs_,\n",
    "            mu_xs = mu_xs,\n",
    "            mu_ys = mu_ys,\n",
    "            mu_xs_ = mu_xs_,\n",
    "            mu_ys_ = mu_ys_,\n",
    "            rec_loss = rec_loss,\n",
    "            kl_loss = kl_loss,\n",
    "            cost = cost,\n",
    "            train = train\n",
    "        )\n",
    "    \n",
    "    # Filter bank takes linear combination of h_dec as these values.\n",
    "    def filterbank(self, gx, gy, sigma2, delta):\n",
    "        # Create a range of float to make points with. This is 1 by 5 tensor\n",
    "        grid_i = tf.reshape(tf.cast(tf.range(self.N), tf.float32), [1, -1])\n",
    "        \n",
    "        # Figure out the center (mean location of filters: 128 by 5 \n",
    "        mu_x = gx + (grid_i - self.N / 2 - 0.5) * delta # Equation 19\n",
    "        mu_y = gy + (grid_i - self.N / 2 - 0.5) * delta # Equation 20\n",
    "        \n",
    "        # This creates an matrix of size 1 by 1 by 28.\n",
    "        # The number contained in here is just [0,1,2,3,4,5,6....,28]\n",
    "        a = tf.reshape(tf.cast(tf.range(self.width), tf.float32), [1, 1, -1])\n",
    "        b = tf.reshape(tf.cast(tf.range(self.width), tf.float32), [1, 1, -1])\n",
    "        \n",
    "        # Reshaping of the above mean locations.\n",
    "        mu_x = tf.reshape(mu_x, [-1, self.N, 1])\n",
    "        mu_y = tf.reshape(mu_y, [-1, self.N, 1])\n",
    "        \n",
    "        # 128 by 5 by 28 for Fx and 128 x 1 x1 for sigma\n",
    "        sigma2 = tf.reshape(sigma2, [-1, 1, 1])\n",
    "        Fx = tf.exp(-tf.square((a - mu_x) / (2*sigma2))) # Equation 25\n",
    "        Fy = tf.exp(-tf.square((b - mu_y) / (2*sigma2))) # Equation 26\n",
    "        \n",
    "        # normalize, sum over A and B dims\n",
    "        # the keeps_sum option retains the sqaushed dimension as length 1.\n",
    "        Fx = Fx/tf.maximum(tf.reduce_sum(Fx,2,keep_dims=True), self.epsilon) # Equation 25 normalization\n",
    "        Fy = Fy/tf.maximum(tf.reduce_sum(Fy,2,keep_dims=True), self.epsilon) # Equation 26 normalization\n",
    "        return Fx, Fy, mu_x, mu_y\n",
    "\n",
    "    # creates attention window with given parameters.\n",
    "    # Returns filter to be applied (128, 5, 28)\n",
    "    def attn_window(self, scope, dec_output, reuse):\n",
    "        \n",
    "        # create attention window with different scopes.\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            params=tf.contrib.slim.fully_connected(dec_output, 5, activation_fn=tf.identity, scope=scope, reuse=reuse)\n",
    "            \n",
    "        # Split the result of dense connection\n",
    "        gx_, gy_, log_sigma2, log_delta, log_gamma=tf.split(params,5,1)\n",
    "        \n",
    "        # figure out the center location of guassian filter.\n",
    "        # I am concerned that gx might just go out of boundary?\n",
    "        # Makes more sense to do tanh transformation on gx_ and gy_?\n",
    "        gx = (self.width+1)/2*(gx_+1) # Equation 22\n",
    "        gy = (self.width+1)/2*(gy_+1) # Equation 23\n",
    "        \n",
    "        # both sigma and gamma is in [0, inf] range.\n",
    "        sigma2 = tf.exp(log_sigma2)\n",
    "        gamma = tf.exp(log_gamma)\n",
    "        \n",
    "        # figuring out the offset from center.\n",
    "        delta=(self.width-1)/(self.N-1)*tf.exp(log_delta) # Equation 24\n",
    "        \n",
    "        return self.filterbank(gx,gy,sigma2,delta)+(gamma,)\n",
    "    \n",
    "    # read with attention \n",
    "    def read_with_attention(self, x, x_hat, dec_output, reuse):\n",
    "        Fx, Fy, _, _, gamma = self.attn_window(\"read\", dec_output, reuse=reuse)\n",
    "        \n",
    "        # the function below implements Equation 27\n",
    "        def filter_img(img,Fx,Fy,gamma,N):\n",
    "            Fxt = tf.transpose(Fx, perm=[0,2,1])\n",
    "            img = tf.reshape(img,[-1, self.width, self.width])\n",
    "            glimpse = tf.matmul(Fy,tf.matmul(img, Fxt))\n",
    "            glimpse = tf.reshape(glimpse,[-1,N*N])\n",
    "            return glimpse*tf.reshape(gamma,[-1,1])\n",
    "        \n",
    "        x = filter_img(x, Fx, Fy, gamma, self.N)\n",
    "        x_hat = filter_img(x_hat, Fx, Fy, gamma, self.N)\n",
    "        return tf.concat([x, x_hat, dec_output], 1)\n",
    "    \n",
    "    # write with attention\n",
    "    def write_with_attention(self, dec_output, reuse):\n",
    "        # Apply linear transfromation to figure out the parameters. \n",
    "        with tf.variable_scope(\"writeW\", reuse=reuse):\n",
    "            w = tf.contrib.slim.fully_connected(dec_output, self.N**2, activation_fn=tf.identity, scope=\"writeW\", reuse=reuse)\n",
    "        \n",
    "        # Create 128 by 5 by 5 image.\n",
    "        w = tf.reshape( w, [self.batchsize, self.N, self.N])\n",
    "        Fx, Fy, mu_x, mu_y, gamma= self.attn_window(\"write\", dec_output, reuse=reuse)\n",
    "        \n",
    "        # Implementing equation 28\n",
    "        Fyt = tf.transpose(Fy, perm=[0,2,1])\n",
    "        wr = tf.matmul(Fyt,tf.matmul(w, Fx))\n",
    "        wr = tf.reshape(wr, [self.batchsize, self.width**2])\n",
    "        \n",
    "        # Gamma is applied at the end to produce 128 by 784 vector.\n",
    "        return wr*tf.reshape(1.0/gamma,[-1,1]), mu_x, mu_y\n",
    "\n",
    "    # Defines a encoder graph\n",
    "    def encode(self, _input, state, reuse=None):\n",
    "        with tf.variable_scope(\"encoder\",reuse = reuse):\n",
    "            # state_is_tuple shouldnt be necessary if you are using modern tensorflow modules.\n",
    "            return self.encoder(_input, state)\n",
    "        \n",
    "    # Defines a decoder graph\n",
    "    def decode(self, _input, state, reuse=None):\n",
    "        with tf.variable_scope(\"decoder\", reuse = reuse):\n",
    "            return self.decoder(_input, state)\n",
    "\n",
    "    # ReparameterizationTrick\n",
    "    def sample(self, mu, log_sigma):\n",
    "        with tf.name_scope(\"sample_reparam\"):\n",
    "            epsilon = tf.random_normal(tf.shape(log_sigma), name=\"0mean1varGaus\")\n",
    "            return mu + epsilon * tf.exp(log_sigma)\n",
    "\n",
    "    # Binary cross-entropy (Adapted from online source)\n",
    "    def crossEntropy(self, obs, actual, offset=1e-7):\n",
    "        with tf.name_scope(\"BinearyXent\"):\n",
    "            obs_ = tf.clip_by_value(obs, offset, 1 - offset)\n",
    "            return -tf.reduce_sum(actual * tf.log(obs_) +\n",
    "                                  (1 - actual) * tf.log(1 - obs_), 1)\n",
    "        \n",
    "    # KL divergence between Gaussian with mu and log_sigma, q(z|x) vs 0-mean 1-variance Gaussian p(z).\n",
    "    def kullbackLeibler(self, mu, log_sigma):\n",
    "        with tf.name_scope(\"KLD\"):\n",
    "            return -0.5 * tf.reduce_sum(1 + 2 * log_sigma - mu**2 - tf.exp(2 * log_sigma), 1)\n",
    "        \n",
    "    # training procedure.\n",
    "    def train(self, X, epochs, valid=None):\n",
    "        # Making the saver object.\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        # Defining the number of batches per epoch\n",
    "        batch_num = int(np.ceil(X.n*1.0/X.batch_size))\n",
    "        if valid != None:\n",
    "            val_batch_num = int(np.ceil(valid.n*1.0/valid.batch_size))\n",
    "        \n",
    "        e = 0\n",
    "        while e < epochs:\n",
    "            \n",
    "            epoch_cost = {\"kld\":[], \"rec\":[], \"cost\":[], \"validcost\":[]}\n",
    "            if e == epochs-1: self.record = {\"cs\":[], \"y\":[], \"mu_x\":[], \"mu_y\":[]}\n",
    "            \n",
    "            for i in range(batch_num):\n",
    "                #Training happens here.\n",
    "                batch = X.next()\n",
    "                feed_dict = {self.ops[\"x\"]: batch[0], self.ops[\"dropout_keepprob\"]: self._dropout}\n",
    "                ops_to_run = [self.ops[\"cost\"], self.ops[\"kl_loss\"], self.ops[\"rec_loss\"], self.ops[\"train\"]]\n",
    "                cost, kld, rec, _= self.sesh.run(ops_to_run, feed_dict)\n",
    "                \n",
    "                #if e == epochs-1: \n",
    "                if True:\n",
    "                    canvas = self.sesh.run(self.ops[\"reconstructed\"], feed_dict)\n",
    "                    canvas = np.stack(canvas, axis=-1)\n",
    "                    mux = self.sesh.run(self.ops[\"mu_xs\"], feed_dict)\n",
    "                    mux = np.stack(mux, axis=-1)\n",
    "                    muy = self.sesh.run(self.ops[\"mu_ys\"], feed_dict)\n",
    "                    muy = np.stack(muy, axis=-1)\n",
    "                    self.record[\"cs\"] = self.record[\"cs\"] + [_ for _ in canvas]\n",
    "                    self.record[\"y\"] = self.record[\"y\"] + [_ for _ in batch[1]]\n",
    "                    self.record[\"mu_x\"] = self.record[\"mu_x\"] + [_ for _ in mux]\n",
    "                    self.record[\"mu_y\"] = self.record[\"mu_y\"] + [_ for _ in muy]\n",
    "                    \n",
    "                epoch_cost[\"kld\"].append(np.mean(kld))\n",
    "                epoch_cost[\"rec\"].append(np.mean(rec))\n",
    "                epoch_cost[\"cost\"].append(cost)\n",
    "            \n",
    "            if valid != None:\n",
    "                for i in range(val_batch_num):\n",
    "                    batch = valid.next()\n",
    "                    feed_dict = {self.ops[\"x\"]: batch[0], self.ops[\"dropout_keepprob\"]: 1.0}\n",
    "                    cost = self.sesh.run(self.ops[\"cost\"], feed_dict)\n",
    "                    epoch_cost[\"validcost\"].append(cost)\n",
    "            self.e+=1\n",
    "            e+= 1\n",
    "                \n",
    "            print \"Epoch:\"+str(self.e), \"train_cost:\", np.mean(epoch_cost[\"cost\"]),\n",
    "            if valid != None: print \"valid_cost:\", np.mean(epoch_cost[\"validcost\"]),\n",
    "            print \"(\", np.mean(epoch_cost[\"kld\"]), np.mean(epoch_cost[\"rec\"]), \")\"\n",
    "            self.learning_curve.append(epoch_cost)\n",
    "            \n",
    "    # Decode latent examples. Other_wise, draw from N(0,1)\n",
    "    def generate(self):\n",
    "        feed_dict = {self.ops[\"dropout_keepprob\"]: 1.0}\n",
    "        canvas = self.sesh.run(self.ops[\"reconstructed_\"], feed_dict)\n",
    "        canvas = np.stack(canvas, axis=-1)\n",
    "        mux = self.sesh.run(self.ops[\"mu_xs_\"], feed_dict)\n",
    "        mux = np.concatenate(mux, axis=2)\n",
    "        muy = self.sesh.run(self.ops[\"mu_ys_\"], feed_dict)\n",
    "        muy = np.concatenate(muy, axis=2)\n",
    "        return canvas, mux, muy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranining a model without attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = DRAW(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 train_cost: 210.838 valid_cost: 176.497 ( 5.57479 205.263 )\n",
      "Epoch:2 train_cost: 160.26 valid_cost: 149.901 ( 11.6155 148.645 )\n",
      "Epoch:3 train_cost: 142.172 valid_cost: 139.093 ( 16.9534 125.218 )\n",
      "Epoch:4 train_cost: 131.263 valid_cost: 130.194 ( 20.3248 110.938 )\n",
      "Epoch:5 train_cost: 124.71 valid_cost: 124.144 ( 21.8096 102.901 )\n",
      "Epoch:6 train_cost: 120.674 valid_cost: 120.07 ( 22.7583 97.9161 )\n",
      "Epoch:7 train_cost: 117.875 valid_cost: 118.283 ( 23.2267 94.6479 )\n",
      "Epoch:8 train_cost: 115.537 valid_cost: 115.27 ( 23.4864 92.0504 )\n",
      "Epoch:9 train_cost: 114.031 valid_cost: 113.814 ( 23.6247 90.4064 )\n",
      "Epoch:10 train_cost: 112.105 valid_cost: 111.99 ( 23.6733 88.4313 )\n",
      "Epoch:11 train_cost: 110.961 valid_cost: 111.325 ( 23.7791 87.1819 )\n",
      "Epoch:12 train_cost: 109.779 valid_cost: 110.019 ( 23.7219 86.0575 )\n",
      "Epoch:13 train_cost: 108.797 valid_cost: 109.345 ( 23.7777 85.019 )\n",
      "Epoch:14 train_cost: 107.794 valid_cost: 107.778 ( 23.7624 84.0318 )\n",
      "Epoch:15 train_cost: 106.877 valid_cost: 108.345 ( 23.6925 83.1844 )\n"
     ]
    }
   ],
   "source": [
    "# Seems like it overfits within just 10 iterations?\n",
    "model.train(train_bf, 60, valid_bf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the drawing process\n",
    "\n",
    "Iteratively reconstruct a sample given a real example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = np.random.randint(50000)\n",
    "sample = model.record[\"cs\"][index].reshape(28,28,10)\n",
    "print \"label:\", np.argmax(model.record[\"y\"][index])\n",
    "plt.figure(figsize=(10,2))\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(sigmoid(sample[:,:,i]), vmin=0, vmax=1)\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a random drawing sample\n",
    "\n",
    "Iteratively generate a sample by drawing from a latent distribution at every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAABVCAYAAADOppJ2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50243b26d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated, mux, muy = model.generate()\n",
    "index = -1\n",
    "images = generated[index].reshape((28, 28, 10))\n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(sigmoid(images[:,:,i]), vmin=0, vmax=1)\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.90965652,   6.58404922,  12.25844288,  17.93283653,  23.60722923], dtype=float32)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mux[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.69745922,   4.95803547,  10.61353016,  16.2690239 ,  21.92451859], dtype=float32)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muy[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
